---
title: "Trabajo Inferencia Estadistica"
output: html_document
date: "2024-11-13"
author:
  - No칠 L칩pez garc칤a
  - Joan Pedro Bruixola
  - Carlos Ribes Garcia
  - Marc Velasco Mateu
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

rm(list=ls())

library(mclust)
library(ggplot2)
```


```{r datos, include=FALSE}
data<-quakes
```

1. Implementa una funci칩n en R para la funci칩n de densidad de probabilidad de la distribuci칩n de mezcla gaussiana. Grafica la funci칩n de densidad de probabilidad de $GM(2,1,5,1,0.3)$. Puedes usar la funci칩n incorporada `dnorm` para la funci칩n de densidad de probabilidad de la distribuci칩n gaussiana.

Implementamos la densidad de la siguiente forma:

```{r ej1.1, echo=TRUE}
densidadmg <- function(x, mu1, sd1, mu2, sd2, w) {
  densidad <- w * dnorm(x, mean = mu1, sd = sd1) + (1-w) * dnorm(x, mean = mu2, sd = sd2)
  return(densidad)
}
```

As칤, podemos visualizar la densidad de la distribuci칩n $GM(2,1,5,1,0.3)$.

```{r ej1.2, echo=FALSE}
# Establecemos el rango de x
x <- seq(-1, 8, length.out = 500)

#Calculamos la densidad
densidad <- densidadmg(x, 2,1,5,1,0.3)

#Graficamos la densidad
plot(x, densidad, type = "l", col = "blue", lwd = 2,
     main = "Densidad de la Mezcla Gaussiana GM(2, 1, 5, 1, 0.3)",
     xlab = "x", ylab = "Densidad")
```

2.Inicialmente, solo observamos los datos de longitud y asumimos que las ubicaciones de longitud son i.i.d. que siguen un modelo de mezcla gaussiana. Estima los cinco par치metros de la mezcla gaussiana utilizando los 1000 valores observados de longitud. Puedes hacer esto num칠ricamente en R con la funci칩n `optim`. Grafica la mezcla gaussiana ajustada sobre el histograma de los datos de longitud.

Para encontrar un buen punto inicial para los par치metros, simplemente puedes observar el histograma de los datos y tratar de adivinar la ubicaci칩n de las medias $\mu_1$ y $\mu_2$. Una suposici칩n inicial para $w$ puede ser la proporci칩n del tama침o de los dos grupos de datos (o usar $w=0.5$ como suposici칩n inicial). Tambi칠n puedes probar diferentes valores iniciales y reportar los resultados con la menor log-verosimilitud negativa.

Dado que hay muchos par치metros, la optimizaci칩n puede llevar mucho tiempo y es probable que debas aumentar el n칰mero m치ximo de iteraciones del algoritmo; de lo contrario, este terminar치 antes de alcanzar un buen 칩ptimo. Puedes hacerlo con `control = list(maxit = 10000)` en la funci칩n `optim`. Probablemente tambi칠n habr치 muchos *warnings*, principalmente porque los par치metros deben estar restringidos, especialmente $w$. Puedes ignorar los *warnings*.

Antes de empezar a buscar los par치metros, representemos el histograma de la variable longitud para encontrar un buen valor inicial para nuestra b칰squeda de par치metros.

```{r ej2.1, echo=FALSE}
p <- ggplot(data, aes(x=long)) + 
  geom_histogram(color="black", fill="white", breaks=(floor(min(data$long))+0.5):(ceiling(max(data$long))-0.5)) +
  labs(title="Histograma de la variable longitud",x="Longitud", y = "Frecuencia")
p
```

Observando el histograma, podemos asignar como medias de las distribuciones separadas $167$ y $182$, pues son los picos m치s altos; desviaciones est치ndar $2$ y $2$, pues los datos no parecen estar muy esparcidos a partir de m치s de $2$ o $4$ unidades; y $w = 0.33$ pues la primera "monta침a" tiene la mitad de altura que la segunda.

Utilizando estos datos como valores iniciales, obtenemos:

```{r ej2.2, echo=FALSE}
#Creamos la funci칩n de log-verosimilitud negativa
log_verosimilitud <- function(params, x) {
  mu1 <- params[1]
  sd1 <- params[2]
  mu2 <- params[3]
  sd2 <- params[4]
  w <- params[5]

  # Calcular la log-verosimilitud negativa
  densidades <- densidadmg(x, mu1, sd1, mu2, sd2, w)
  return(-sum(log(densidades)))
}

# Buscamos los valores optimizando
resultado <- optim(
  par = c(167,2,182,2,0.3),
  fn = log_verosimilitud,
  x = data$long,
  method = "L-BFGS-B",
  lower = c(-Inf, 0.01, -Inf, 0.01, 0.01),
  upper = c(Inf, Inf, Inf, Inf, 0.99)
)

cat("Estimaci칩n del par치metro mu1:",resultado$par[1],"\n")
cat("Estimaci칩n del par치metro sd1:",resultado$par[2],"\n")
cat("Estimaci칩n del par치metro mu2:",resultado$par[3],"\n")
cat("Estimaci칩n del par치metro sd2:",resultado$par[4],"\n")
cat("Estimaci칩n del par치metro w:",resultado$par[5],"\n")
```
Para comprobar si realmente estos son una buena estimaci칩n, dibujamos la densidad de una mezcla gaussiana de estos par치metros sobre el histograma anterior.

```{r ej2.3, echo=FALSE}
x <- seq(165,189,length.out = 240)
y <- densidadmg(x, resultado$par[1],resultado$par[2],resultado$par[3],resultado$par[4],resultado$par[5])

# Crear el histograma
hist(data$long, breaks = 30, probability = TRUE, col = "gray", xlab = "Longitud", ylab = "Densidad", main = "")

# Superponer la curva de densidad
title <- "Densidad de mezcla gausiana sobre histograma de la longitud"
lines(x, y, col = "blue", lwd = 2, lty = 1)
title(main = title)
```

Claramente, nuestra estimaci칩n era correcta, y los datos se ajustan perfectamente a esta distribuci칩n.

3.Considera ahora otro modelo en el que las ubicaciones de longitud son independientes y distribuidas de manera gaussiana $N(\mu,\sigma^2)$. Ajusta este modelo a los datos observados de longitud.

Como valores iniciales, escogemos la media y la desviaci칩n t칤pica de nuestras observaciones, que en este caso son $179.462$ y $6.066461$.

De esta manera, obtenemos las estimaciones:

```{r ej3.1, echo=FALSE}
#Creamos la funci칩n de log-verosimilitud negativa
log_verosimilitud2 <- function(params, x) {
  mu <- params[1]
  sd <- params[2]

  # Calcular la log-verosimilitud negativa
  densidades <- dnorm(x, mean = mu, sd = sd)
  return(-sum(log(densidades)))
}

# Buscamos los valores optimizando
resultado2 <- optim(
  par = c(mean(data$long),sd(data$long)),
  fn = log_verosimilitud2,
  x = data$long,
  method = "L-BFGS-B",
  lower = c(-Inf, 0.01),
  upper = c(Inf, Inf)
)

cat("Estimaci칩n del par치metro mu:",resultado2$par[1],"\n")
cat("Estimaci칩n del par치metro sd:",resultado2$par[2],"\n")
```

Obviamente, las estimaciones coinciden con la media y la desviaci칩n t칤pica de nuestros datos, pues estos estimadores son los estimadores de m치xima verosimilitud para distribuciones normales.

Con estos par치metros estimados, podemos superponer nuestra densidad aproximada sobre el histograma, para estudiar visualmente si este ser칤a un buen modelo.

```{r ej3.2, echo=FALSE}
x <- seq(165,189,length.out = 240)
y <- dnorm(x, resultado2$par[1],resultado2$par[2])

# Crear el histograma
hist(data$long, breaks = 30, probability = TRUE, col = "gray", xlab = "Longitud", ylab = "Densidad", main = "")

# Superponer la curva de densidad
title <- "Densidad de mezcla gausiana sobre histograma de la longitud"
lines(x, y, col = "blue", lwd = 2, lty = 1)
title(main = title)
```

Es obvio que no podemos asumir que nuestros datos siguen una distribuci칩n normal, pues el ajuste es p칠simo.

4.Calcula los valores de AIC y BIC para el modelo gaussiano simple y el modelo de mezcla gaussiana para los datos de longitud. 쯈u칠 modelo deber칤a seleccionarse?

```{r}
# Definimos las funciones para calcular el AIC y BIC a partir de las logverosimilitudes
AICfromL <- function(x, params, LogLike){
  return(  2*length(params) + 2*LogLike(params,x) ) #Sumamos en vez de restar porque las LogVerosimilitudes las hemos cambiado de signo
}
BICfromL <- function(x, params, LogLike){
  return( length(params)*log(length(x)) + 2*LogLike(params,x) ) # idem a AICfromL
}

#AIC y BIC del modelo gaussiano simple:

AICsimple <- AICfromL(data$long, params = resultado2$par, log_verosimilitud2)
BICsimple <- BICfromL(data$long, params = resultado2$par, log_verosimilitud2)

cat('\nResultados de los criterios AIC y BIC para el modelo simple: \nAIC:', AICsimple,'\nBIC:', BICsimple)

#AIC y BIC del modelo gaussiano ponderado:
AICponderado <- AICfromL(data$long, params = resultado$par, log_verosimilitud)
BICponderado <- BICfromL(data$long, params = resultado$par, log_verosimilitud)

cat('\n\nResultados de los criterios AIC y BIC para el modelo ponderado: \nAIC:', AICponderado,'\nBIC:', BICponderado)


```
Con lo que se tiene que ambos criterios se decantan por el modelo ponderado ante el modelo simple.

5.Repite el procedimiento de ajuste anterior para los datos de latitud y profundidad, y realiza la selecci칩n de modelos como de costumbre utilizando AIC y BIC. 쯈u칠 modelo deber칤a seleccionarse?

En primer lugar hacemos el estudio de latitud:
```{r}
resultado_lat_simple <- optim(
  par = c(mean(data$lat), sd(data$lat)),
  fn = log_verosimilitud2,
  x = data$lat,
  method = "L-BFGS-B",
  lower = c(-Inf, 0.01, -Inf, 0.01, 0.01),
  upper = c(Inf, Inf, Inf, Inf, 0.99)
)

resultado_lat_pond <- optim(
  par = c(15,2,25,2,0.3),
  fn = log_verosimilitud,
  x = data$lat,
  method = "L-BFGS-B",
  lower = c(-Inf, 0.01, -Inf, 0.01, 0.01),
  upper = c(Inf, Inf, Inf, Inf, 0.99)
)

AIC_lat_simple <- AICfromL(data$lat, params = resultado_lat_simple$par, log_verosimilitud2)
BIC_lat_simple <- BICfromL(data$lat, params = resultado_lat_simple$par, log_verosimilitud2)

cat('\nResultados de los criterios AIC y BIC para el modelo simple aplicado a latitud son: \nAIC:', AIC_lat_simple,'\nBIC:', BIC_lat_simple)

AIC_lat_pond <- AICfromL(data$lat, params = resultado_lat_pond$par, log_verosimilitud)
BIC_lat_pond <- BICfromL(data$lat, params = resultado_lat_pond$par, log_verosimilitud)

cat('\nResultados de los criterios AIC y BIC para el modelo ponderado aplicado a latitud son: \nAIC:', AIC_lat_pond,'\nBIC:', BIC_lat_pond)

```
Y a continuaci칩n de la profundidad:
```{r}
resultado_prof_simple <- optim(
  par = c(mean(data$depth), sd(data$depth)),
  fn = log_verosimilitud2,
  x = data$depth,
  method = "L-BFGS-B",
  lower = c(-Inf, 0.01, -Inf, 0.01, 0.01),
  upper = c(Inf, Inf, Inf, Inf, 0.99)
)

hist(data$depth)

resultado_prof_pond <- optim(
  par = c(100,2,600,2,0.6), #Inicializamos viendo en el histograma d칩nde parecen estar los dos centros de las gaussianas
  fn = log_verosimilitud,
  x = data$depth,
  method = "L-BFGS-B",
  lower = c(-Inf, 0.01, -Inf, 0.01, 0.01),
  upper = c(Inf, Inf, Inf, Inf, 0.99)
)

AIC_prof_simple <- AICfromL(data$lat, params = resultado_lat_simple$par, log_verosimilitud2)
BIC_prof_simple <- BICfromL(data$lat, params = resultado_lat_simple$par, log_verosimilitud2)

cat('\nResultados de los criterios AIC y BIC para el modelo simple aplicado a latitud son: \nAIC:', AIC_prof_simple,'\nBIC:', BIC_prof_simple)

AIC_prof_pond <- AICfromL(data$lat, params = resultado_prof_pond$par, log_verosimilitud)
BIC_prof_pond <- BICfromL(data$lat, params = resultado_prof_pond$par, log_verosimilitud)

cat('\nResultados de los criterios AIC y BIC para el modelo ponderado aplicado a latitud son: \nAIC:', AIC_prof_pond,'\nBIC:', BIC_prof_pond)

```
En este caso vemos que el modelo simple nos da mejores resultados tanto para el criterio AIC como para el BIC.


6.Considera los dos grupos de eventos y calcula el valor medio e intervalos de confianza (95 %) para la media de las longitudes, latitudes y profundidades en los dos grupos (azul y rojo en la Figura 1). 쯈u칠 conclusiones podemos sacar de los intervalos de confianza?
```{r}

```


7.Consideramos ahora la variable n칰mero de estaciones s칤smicas que detectaron el evento (stations). 쯇odemos afirmar que el n칰mero medio de estaciones que detectaron los eventos es significativamente distinto en los dos grupos de terremotos (a nivel 洧띺=0.01풤=0.01 y a nivel 洧띺=0.1풤=0.1)? (Puedes utilizar bootstrap y/o asumir poblaciones normales).

```{r}

```


