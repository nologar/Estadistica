---
title: "Trabajo Inferencia Estadistica"
output: html_document
date: "2024-11-13"
author:
  - No칠 L칩pez garc칤a
  - Joan Pedro Bruixola
  - Carlos Ribes Garcia
  - Marc Velasco Mateu
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

rm(list=ls())

library(mclust)
library(ggplot2)
library(dplyr)
library(tidyr)
```


```{r datos, include=FALSE}
data<-quakes
```

## Ejercicio 1
**Implementa una funci칩n en R para la funci칩n de densidad de probabilidad de la distribuci칩n de mezcla gaussiana. Grafica la funci칩n de densidad de probabilidad de $GM(2,1,5,1,0.3)$. Puedes usar la funci칩n incorporada `dnorm` para la funci칩n de densidad de probabilidad de la distribuci칩n gaussiana.**

Implementamos la densidad de la siguiente forma:

```{r ej1.1, echo=TRUE}
densidadmg <- function(x, mu1, sd1, mu2, sd2, w) {
  densidad <- w * dnorm(x, mean = mu1, sd = sd1) + (1-w) * dnorm(x, mean = mu2, sd = sd2)
  return(densidad)
}
```

As칤, podemos visualizar la densidad de la distribuci칩n $GM(2,1,5,1,0.3)$.

```{r ej1.2, echo=FALSE}
# Establecemos el rango de x
x <- seq(-1, 8, length.out = 500)

#Calculamos la densidad
densidad <- densidadmg(x, 2,1,5,1,0.3)

#Graficamos la densidad
plot(x, densidad, type = "l", col = "blue", lwd = 2,
     main = "Densidad de la Mezcla Gaussiana GM(2, 1, 5, 1, 0.3)",
     xlab = "x", ylab = "Densidad")
```

## Ejercicio 2
**Inicialmente, solo observamos los datos de longitud y asumimos que las ubicaciones de longitud son i.i.d. que siguen un modelo de mezcla gaussiana. Estima los cinco par치metros de la mezcla gaussiana utilizando los 1000 valores observados de longitud. Puedes hacer esto num칠ricamente en R con la funci칩n `optim`. Grafica la mezcla gaussiana ajustada sobre el histograma de los datos de longitud.**

**Para encontrar un buen punto inicial para los par치metros, simplemente puedes observar el histograma de los datos y tratar de adivinar la ubicaci칩n de las medias $\mu_1$ y $\mu_2$. Una suposici칩n inicial para $w$ puede ser la proporci칩n del tama침o de los dos grupos de datos (o usar $w=0.5$ como suposici칩n inicial). Tambi칠n puedes probar diferentes valores iniciales y reportar los resultados con la menor log-verosimilitud negativa.**

**Dado que hay muchos par치metros, la optimizaci칩n puede llevar mucho tiempo y es probable que debas aumentar el n칰mero m치ximo de iteraciones del algoritmo; de lo contrario, este terminar치 antes de alcanzar un buen 칩ptimo. Puedes hacerlo con `control = list(maxit = 10000)` en la funci칩n `optim`. Probablemente tambi칠n habr치 muchos *warnings*, principalmente porque los par치metros deben estar restringidos, especialmente $w$. Puedes ignorar los *warnings*.**

Antes de empezar a buscar los par치metros, representemos el histograma de la variable longitud para encontrar un buen valor inicial para nuestra b칰squeda de par치metros.

```{r ej2.1, echo=FALSE}
p <- ggplot(data, aes(x=long)) + 
  geom_histogram(color="black", fill="white", breaks=(floor(min(data$long))+0.5):(ceiling(max(data$long))-0.5)) +
  labs(title="Histograma de la variable longitud",x="Longitud", y = "Frecuencia")
p
```

Observando el histograma, podemos asignar como medias de las distribuciones separadas $167$ y $182$, pues son los picos m치s altos; desviaciones est치ndar $2$ y $2$, pues los datos no parecen estar muy esparcidos a partir de m치s de $2$ o $4$ unidades; y $w = 0.33$ pues la primera "monta침a" tiene la mitad de altura que la segunda.

Utilizando estos datos como valores iniciales, obtenemos:

```{r ej2.2, echo=FALSE}
#Creamos la funci칩n de log-verosimilitud negativa
log_verosimilitud <- function(params, x) {
  mu1 <- params[1]
  sd1 <- params[2]
  mu2 <- params[3]
  sd2 <- params[4]
  w <- params[5]

  # Calcular la log-verosimilitud negativa
  densidades <- densidadmg(x, mu1, sd1, mu2, sd2, w)
  return(-sum(log(densidades)))
}

# Buscamos los valores optimizando
resultado <- optim(
  par = c(167,2,182,2,0.3),
  fn = log_verosimilitud,
  x = data$long,
  method = "L-BFGS-B",
  lower = c(-Inf, 0.01, -Inf, 0.01, 0.01),
  upper = c(Inf, Inf, Inf, Inf, 0.99)
)

cat("Estimaci칩n del par치metro mu1:",resultado$par[1],"\n")
cat("Estimaci칩n del par치metro sd1:",resultado$par[2],"\n")
cat("Estimaci칩n del par치metro mu2:",resultado$par[3],"\n")
cat("Estimaci칩n del par치metro sd2:",resultado$par[4],"\n")
cat("Estimaci칩n del par치metro w:",resultado$par[5],"\n")
```
Para comprobar si realmente estos son una buena estimaci칩n, dibujamos la densidad de una mezcla gaussiana de estos par치metros sobre el histograma anterior.

```{r ej2.3, echo=FALSE}
x <- seq(165,189,length.out = 240)
y <- densidadmg(x, resultado$par[1],resultado$par[2],resultado$par[3],resultado$par[4],resultado$par[5])

# Crear el histograma
hist(data$long, breaks = 30, probability = TRUE, col = "gray", xlab = "Longitud", ylab = "Densidad", main = "")

# Superponer la curva de densidad
title <- "Densidad de mezcla gausiana sobre histograma de la longitud"
lines(x, y, col = "blue", lwd = 2, lty = 1)
title(main = title)
```

Claramente, nuestra estimaci칩n era correcta, y los datos se ajustan perfectamente a esta distribuci칩n.

## Ejercicio 3
**Considera ahora otro modelo en el que las ubicaciones de longitud son independientes y distribuidas de manera gaussiana $N(\mu,\sigma^2)$. Ajusta este modelo a los datos observados de longitud.**

Como valores iniciales, escogemos la media y la desviaci칩n t칤pica de nuestras observaciones, que en este caso son $179.462$ y $6.066461$.

De esta manera, obtenemos las estimaciones:

```{r ej3.1, echo=FALSE}
#Creamos la funci칩n de log-verosimilitud negativa
log_verosimilitud2 <- function(params, x) {
  mu <- params[1]
  sd <- params[2]

  # Calcular la log-verosimilitud negativa
  densidades <- dnorm(x, mean = mu, sd = sd)
  return(-sum(log(densidades)))
}

# Buscamos los valores optimizando
resultado2 <- optim(
  par = c(mean(data$long),sd(data$long)),
  fn = log_verosimilitud2,
  x = data$long,
  method = "L-BFGS-B",
  lower = c(-Inf, 0.01),
  upper = c(Inf, Inf)
)

cat("Estimaci칩n del par치metro mu:",resultado2$par[1],"\n")
cat("Estimaci칩n del par치metro sd:",resultado2$par[2],"\n")
```

Obviamente, las estimaciones coinciden con la media y la desviaci칩n t칤pica de nuestros datos, pues estos estimadores son los estimadores de m치xima verosimilitud para distribuciones normales.

Con estos par치metros estimados, podemos superponer nuestra densidad aproximada sobre el histograma, para estudiar visualmente si este ser칤a un buen modelo.

```{r ej3.2, echo=FALSE}
x <- seq(165,189,length.out = 240)
y <- dnorm(x, resultado2$par[1],resultado2$par[2])

# Crear el histograma
hist(data$long, breaks = 30, probability = TRUE, col = "gray", xlab = "Longitud", ylab = "Densidad", main = "")

# Superponer la curva de densidad
title <- "Densidad de mezcla gausiana sobre histograma de la longitud"
lines(x, y, col = "blue", lwd = 2, lty = 1)
title(main = title)
```

Es obvio que no podemos asumir que nuestros datos siguen una distribuci칩n normal, pues el ajuste es p칠simo.

## Ejercicio 4
**Calcula los valores de AIC y BIC para el modelo gaussiano simple y el modelo de mezcla gaussiana para los datos de longitud. 쯈u칠 modelo deber칤a seleccionarse?**

```{r ej4.1, echo=FALSE}
# Definimos las funciones para calcular el AIC y BIC a partir de las logverosimilitudes
AICfromL <- function(x, params, LogLike){
  return(  2*length(params) + 2*LogLike(params,x) ) #Sumamos en vez de restar porque las LogVerosimilitudes las hemos cambiado de signo
}
BICfromL <- function(x, params, LogLike){
  return( length(params)*log(length(x)) + 2*LogLike(params,x) ) # idem a AICfromL
}

#AIC y BIC del modelo gaussiano simple:
AICsimple <- AICfromL(data$long, params = resultado2$par, log_verosimilitud2)
BICsimple <- BICfromL(data$long, params = resultado2$par, log_verosimilitud2)

cat('Resultados de los criterios AIC y BIC para el modelo simple: \nAIC:', AICsimple,'\nBIC:', BICsimple)

#AIC y BIC del modelo gaussiano ponderado:
AICponderado <- AICfromL(data$long, params = resultado$par, log_verosimilitud)
BICponderado <- BICfromL(data$long, params = resultado$par, log_verosimilitud)

cat('Resultados de los criterios AIC y BIC para el modelo ponderado: \nAIC:', AICponderado,'\nBIC:', BICponderado)
```
Como vemos, ambos criterios se decantan por el modelo ponderado ante el modelo simple.

## Ejercicio 5
**Repite el procedimiento de ajuste anterior para los datos de latitud y profundidad, y realiza la selecci칩n de modelos como de costumbre utilizando AIC y BIC. 쯈u칠 modelo deber칤a seleccionarse?**

En primer lugar hacemos el estudio de latitud:

```{r ej5.1, echo = FALSE, warning=FALSE}
resultado_lat_simple <- optim(
  par = c(mean(data$lat), sd(data$lat)),
  fn = log_verosimilitud2,
  x = data$lat,
  method = "L-BFGS-B",
  lower = c(-Inf, 0.01, -Inf, 0.01, 0.01),
  upper = c(Inf, Inf, Inf, Inf, 0.99)
)

resultado_lat_pond <- optim(
  par = c(15,2,25,2,0.3),
  fn = log_verosimilitud,
  x = data$lat,
  method = "L-BFGS-B",
  lower = c(-Inf, 0.01, -Inf, 0.01, 0.01),
  upper = c(Inf, Inf, Inf, Inf, 0.99)
)

AIC_lat_simple <- AICfromL(data$lat, params = resultado_lat_simple$par, log_verosimilitud2)
BIC_lat_simple <- BICfromL(data$lat, params = resultado_lat_simple$par, log_verosimilitud2)

cat('Resultados de los criterios AIC y BIC para el modelo simple aplicado a latitud son: \nAIC:', AIC_lat_simple,'\nBIC:', BIC_lat_simple)

AIC_lat_pond <- AICfromL(data$lat, params = resultado_lat_pond$par, log_verosimilitud)
BIC_lat_pond <- BICfromL(data$lat, params = resultado_lat_pond$par, log_verosimilitud)

cat('Resultados de los criterios AIC y BIC para el modelo ponderado aplicado a latitud son: \nAIC:', AIC_lat_pond,'\nBIC:', BIC_lat_pond)

densidadobtenidalat  <- densidadmg( data$lat, resultado_lat_pond$par[1], resultado_lat_pond$par[2], resultado_lat_pond$par[3], resultado_lat_pond$par[4], resultado_lat_pond$par[5] )

ggplot(data = data)+
  geom_histogram( aes(x = lat, y = ..density..), binwidth=1 )+
  geom_line( aes( x = lat, y = densidadobtenidalat), linewidth = 1, col = "red")+
  geom_line( aes( x = lat,y = dnorm(lat, resultado_lat_simple$par[1],resultado_lat_simple$par[2])), linewidth = 1, col = "blue")
```

Vemos que los modelos s칩n pr치cticamente id칠nticos, lo que se debe a que el modelo de mezcla ha considerado pr치cticamente solo una gaussiana:

```{r ej5.2, echo=FALSE}
cat("Par치metro peso estimado:",resultado_lat_pond$par[5])
```

Es por este motivo que el modelo simple, que tiene menos par치metros, salga beneficiado del criterio AIC/BIC.

Hacemos ahora un estudio de la distribuci칩n de la profundidad:

```{r ej5.3,echo=FALSE, warning = FALSE}
resultado_prof_simple <- optim(
  par = c(mean(data$depth), sd(data$depth)),
  fn = log_verosimilitud2,
  x = data$depth,
  method = "L-BFGS-B",
  lower = c(-Inf, 0.01, -Inf, 0.01, 0.01),
  upper = c(Inf, Inf, Inf, Inf, 0.99)
)

resultado_prof_pond <- optim(
  par = c(75,60,600,150,0.7), #Inicializamos viendo en el histograma d칩nde parecen estar los dos centros de las gaussianas 170, 600
  fn = log_verosimilitud,
  x = data$depth,
  method = "L-BFGS-B",
  lower = c(0, 0.01, -Inf, 0.01, 0.01),
  upper = c(Inf, Inf, Inf, Inf, 0.99)
)

AIC_prof_simple <- AICfromL(data$lat, params = resultado_lat_simple$par, log_verosimilitud2)
BIC_prof_simple <- BICfromL(data$lat, params = resultado_lat_simple$par, log_verosimilitud2)

cat('Resultados de los criterios AIC y BIC para el modelo simple aplicado a profundidad son: \nAIC:', AIC_prof_simple,'\nBIC:', BIC_prof_simple)

AIC_prof_pond <- AICfromL(data$lat, params = resultado_prof_pond$par, log_verosimilitud)
BIC_prof_pond <- BICfromL(data$lat, params = resultado_prof_pond$par, log_verosimilitud)

cat('Resultados de los criterios AIC y BIC para el modelo ponderado aplicado a profundidad son: \nAIC:', AIC_prof_pond,'\nBIC:', BIC_prof_pond)

Xaxis <- seq(-200,800, by = 1)
densidadobtenidaX <- densidadmg( Xaxis, resultado_prof_pond$par[1], resultado_prof_pond$par[2], resultado_prof_pond$par[3], resultado_prof_pond$par[4], resultado_prof_pond$par[5] )
densidadobtenidadepth  <- densidadmg( data$depth, resultado_prof_pond$par[1], resultado_prof_pond$par[2], resultado_prof_pond$par[3], resultado_prof_pond$par[4], resultado_prof_pond$par[5] )

ggplot(data = data)+
  geom_histogram( aes(x = depth, y = ..density..), binwidth = 10 )+
  geom_line( aes( x = depth, y = densidadobtenidadepth), linewidth = 1, col = "red")+
  geom_line( aes( x = depth,y = dnorm(depth, resultado_prof_simple$par[1],resultado_prof_simple$par[2])), linewidth = 1, col = "blue")
```

En este caso vemos que el modelo simple nos da mejores resultados tanto para el criterio AIC como para el BIC. Y esto puede desconcertar un poco en vista del aspecto de la gr치fica anterior, pero tenemos que tener en cuenta que las funciones de densidad gaussianas tienen soporte infinito, y por tanto, si visualzamos un poco m치s del eje X:

```{r ej5.4, echo=FALSE}
ggplot()+
  geom_histogram( data = data, aes(x = depth, y = ..density..) , binwidth = 10)+
  geom_line( aes( x = Xaxis, y = densidadobtenidaX), linewidth = 1, col = "red")+
  geom_line( aes( x = Xaxis,y = dnorm(Xaxis, resultado_prof_simple$par[1],resultado_prof_simple$par[2])), linewidth = 1, col = "blue")
```

Nos damos cuenta de que ambos modelos fallan en estos puntos fuera del rango de valores de 'depth', con lo que no es extra침o que se priorice un modelo con 3 par치metros menos.

## Ejercicio 6
**Considera los dos grupos de eventos y calcula el valor medio e intervalos de confianza (95%) para la media de las longitudes, latitudes y profundidades en los dos grupos (azul y rojo en la Figura 1). 쯈u칠 conclusiones podemos sacar de los intervalos de confianza?**

```{r ej6.1, message=FALSE, warning=FALSE,echo=FALSE}
data$class <- ifelse(data$long > 175, "Tonga trench", "Plate junction")

# Separamos en un dataset por evento

data_Tonga<-data %>%
  filter(class=="Tonga trench")

data_Plate<- data %>%
  filter(class=="Plate junction")

# Funci칩n para calcular intervalos de confianza (formato aseado)
intervalo_confianza <- function(x, nivel = 0.95) {
  n <- length(x)
  mean_x <- mean(x)
  se <- sd(x) / sqrt(n)  # Error est치ndar
  error <- qt((1 + nivel) / 2, df = n - 1) * se
  c(Media = mean_x, LI = mean_x - error, LS = mean_x + error)
}

# Procesar datos para Tonga Trench
resultados_tonga <- data_Tonga %>%
  summarise(
    Longitud = intervalo_confianza(long),
    Latitud = intervalo_confianza(lat),
    Profundidad = intervalo_confianza(depth)
  )

# Trasponer y renombrar columnas para Tonga
resultados_tonga <- as.data.frame(t(resultados_tonga))  # Transponer
colnames(resultados_tonga) <- c("Media", "Valor inferior", "Valor superior")  # Renombrar columnas

# Procesar datos para Plate Junction
resultados_plate <- data_Plate %>%
  summarise(
    Longitud = intervalo_confianza(long),
    Latitud = intervalo_confianza(lat),
    Profundidad = intervalo_confianza(depth)
  )

# Trasponer y renombrar columnas para Plate
resultados_plate <- as.data.frame(t(resultados_plate))  # Transponer
colnames(resultados_plate) <- c("Media", "Valor inferior", "Valor superior")  # Renombrar columnas
```

Empleando la distinci칩n del archivo quakes_plot se ha separado el dataframe en los datos corresponientes a la Tonga y a uni칩n de las placas. Primeramente, se muestran los resultados obtenidos para los datos correspondientes a la Tonga.

```{r ej6.2 , message=FALSE, warning=FALSE,echo=FALSE}
# Mostrar resultados
# Resultados de Tonga
print(resultados_tonga)
```

Ahora se muestran los resultados para la uni칩n de las placas.

```{r ej6.3, message=FALSE, warning=FALSE,echo=FALSE}
#Resultados para Plate junction
print(resultados_plate)
```

Finalmente, como vemos los intervalos de confianza nos permiten estimar el rango en el que se encuentra la media verdadera de las variables analizadas (longitud, latitud y profundidad) con un nivel de confianza del 95 %. En este caso, se observa que los intervalos de confianza de cada variable no se solapan entre los dos grupos (Tonga trench y Plate junction). Esto confirma que existen diferencias estad칤sticamente significativas entre ambos conjuntos de eventos.

En particular, las diferencias en las medias y los intervalos reflejan caracter칤sticas claramente distintas:

* En longitud, los eventos del grupo Tonga trench se encuentran en regiones m치s al este, mientras que Plate junction est치 m치s al oeste. Esto es coherente con lo que se ve claramente en el mapa que se nos proporciona en la pr치ctica.

* En latitud, los eventos de Tonga trench est치n ubicados en su mayor칤a m치s al sur, en comparaci칩n con Plate junction.

* En profundidad, los eventos de Tonga trench se producen a mayores profundidades, lo que es consistente pues se trata de una fosa , mientras que los eventos de Plate junction ocurren en zonas m치s superficiales.

Estos resultados muestran que nos encontramos ante dos fen칩menos claramente distintos.

## Ejercicio 7
**Consideramos ahora la variable n칰mero de estaciones s칤smicas que detectaron el evento (stations). 쯇odemos afirmar que el n칰mero medio de estaciones que detectaron los eventos es significativamente distinto en los dos grupos de terremotos (a nivel 洧띺=0.01 y a nivel 풤=0.1)? (Puedes utilizar bootstrap y/o asumir poblaciones normales).**

Para responder a la pregunta que se plantea realizaremos un contraste de hip칩tesis sobre las medias de los grupos:
$H_{0}: \mu_{1} = \mu_{2}$, $H_{1}: \mu_{1} \neq \mu_{2}$.

```{r ej7.1, echo=FALSE}
# Dividir los datos en dos grupos seg칰n la magnitud
grupo1 <- data$stations[data$class == "Tonga trench"]
grupo2 <- data$stations[data$class == "Plate junction"]
```

El contraste lo podr칤amos resolver mediante un test t-student bilateral, pero primero tenemos que estudiar si las poblaciones son aproximadamente normales. Primero, haremos un histograma y veremos si las distribuciones parecen normales:

```{r ej7.2, echo=FALSE}
par(mfrow = c(1, 2)) 

# Histograma para el grupo "Tonga trench"
hist(grupo1, 
     breaks = 20, 
     col = "lightblue", 
     main = "Tonga trench", 
     xlab = "Stations", 
     probability = TRUE)
lines(density(grupo1), col = "darkblue", lwd = 2)

# Histograma para el grupo "Plate junction"
hist(grupo2, 
     breaks = 20, 
     col = "lightgreen", 
     main = "Plate junction", 
     xlab = "Stations", 
     probability = TRUE)
lines(density(grupo2), col = "darkgreen", lwd = 2)
```

Observamos que los histogramas nos muestran una distribuci칩n de los datos que no parece normal. Para confirmarlo, hacemos un test shapiro-wilk:

```{r ej7.3, echo=FALSE}
shapiro.test(grupo1) # para el grupo Tonga trench
shapiro.test(grupo2) # para el grupo Plate junction
```

Por tanto, podemos confirmar que los grupos no siguen una distribuci칩n normal. Esto implica que no podemos asumir normalidad, y por tanto no podemos aplicar un test t-student. Por eso, utilizaremos una t칠cnica bootstrap. Lo que haremos es hacer intervalos de confianzaa niveles 99% y 90% para las diferencias de las medias de muestras generadas con bootstrap y veremos si el 0 est치. Es decir, estamos resolviendo el contraste: $H_{0}: \mu_{1} - \mu_{2} = 0$, $H_{1}: \mu_{1} - \mu_{2} \neq 0$.

```{r ej7.4, echo=FALSE}
set.seed(123) # Para reproducibilidad

# Crear una funci칩n para calcular la diferencia de medias
diff_means <- function(data1, data2) {
  mean(data1) - mean(data2)
}

# Bootstrap
n_boot <- 10000
boot_diff <- replicate(n_boot, {
  sample1 <- sample(grupo1, length(grupo1), replace = TRUE)
  sample2 <- sample(grupo2, length(grupo2), replace = TRUE)
  diff_means(sample1, sample2)
})

# Intervalo de confianza al 99% y al 90%
ci_99 <- quantile(boot_diff, probs = c(0.005, 0.995))
ci_90 <- quantile(boot_diff, probs = c(0.05, 0.95))

print(ci_99)
print(ci_90)

# Verificar si el intervalo incluye 0
if (ci_99[1] > 0 || ci_99[2] < 0) {
  cat("Rechazamos H0 al nivel de significancia 0.01\n")
} else {
  cat("No podemos rechazar H0 al nivel de significancia 0.01\n")
}

if (ci_90[1] > 0 || ci_90[2] < 0) {
  cat("Rechazamos H0 al nivel de significancia 0.1\n")
} else {
  cat("No podemos rechazar H0 al nivel de significancia 0.1\n")
}
```

Es decir, con un nivel de significancia de 0.01 no tenemos evidencia suficiente para decir que las medias de los grupos no son iguales. En cambio, para un nivel de 0.1 si que tenemos evidencia estad칤stica suficiente para afirmar que las medias de los grupos son distintas.