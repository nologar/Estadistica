---
title: "Trabajo Series Temporales"
author:
- false
- Joan Pedro Bruixola
- Carlos Ribes Garcia
- Marc Velasco Mateu
date: "2024-11-13"
output:
  pdf_document: default
  html_document: default

---

```{r setup, include=FALSE}
library(lubridate)
library(zoo)
library(dplyr)
library(imputeTS)

knitr::opts_chunk$set(echo = TRUE)

rm(list = ls())
```

# Análisis de los datos diarios de temperatura media

El fichero 'TG_STAID000455.txt' incluye los datos de temperatura media diaria, registrados en la estación meteorológica de Tenerife-Los Rodeos. En este trabajo vamos a analizar esta serie temporal.

```{r datos, echo=FALSE, message=FALSE, warning=FALSE}
df<- read.csv("./TG_STAID000455.txt", skip = 20, header = TRUE, sep = ",")
df$DATE<- ymd(df$DATE)
```

## Ejercicio 1
**Realizar gráficos que describan la serie original. Comprobar mediante algún método gráfico si existe estacionalidad anual.**

Primero vamos a visualizar la serie temporal.

```{r ej11, echo=FALSE}
# Gráfico de líneas para la serie temporal
plot(df$DATE, df$TG, type = "l", col = "blue", 
     xlab = "Fecha", ylab = "Temperatura Media (TG)", 
     main = "Evolución de la Temperatura Media")
```

Notamos que esta mala visualización se debe a los datos perdidos que tenemos en la variable TG. Sabemos que estos están etiquetados con un 9 en la variable Q_TG.

```{r ej12, echo=FALSE}
head(df[df$Q_TG== 9,])
```

Notamos que los valores perdidos están asociados al valor -9999. Vamos a cambiarlo para que tengan el valor asociado NA.

```{r ej13, echo=FALSE}
df$TG[df$Q_TG== 9]=NA
head(df[df$Q_TG== 9,])
```

Ahora representamos la serie temporal excluyendo los NA's.

```{r ej14, echo=FALSE, message=FALSE, warning=FALSE}
df_clean <- df %>% na.omit()

plot(df_clean$DATE, df_clean$TG, type = "l", col = "blue", 
     xlab = "Fecha", ylab = "Temperatura Media (TG)", 
     main = "Evolución de la Temperatura Media")
```

También podemos hacer un histograma para analizar la distribución de las temperaturas.

```{r ej15, echo=FALSE}
# Histograma de la temperatura media
hist(df_clean$TG, breaks = 20, col = "lightblue", 
     xlab = "Temperatura Media (TG)",
     ylab = "Frecuencia",
     main = "Distribución de la Temperatura Media")
```

También podemos analizar la dispersión y los posibles outliers con un boxplot.

```{r ej16, echo=FALSE}
# Boxplot de la temperatura media
boxplot(df_clean$TG, horizontal = TRUE, col = "orange", 
        main = "Dispersión de la Temperatura Media", 
        xlab = "Temperatura Media (TG)")
```

Se pueden observar muchos outliers. Seguramente, la mayoría de ellos serán aquellos valores etiquetados  con un 1 en la variable Q_TG.

```{r ej17, echo=FALSE}
df[df$Q_TG== 1,]
```

Notamos que efectivamente todos estos valores están fuera de los bigotes del boxplot.

Ahora veremos mediante algún método gráfico si existe estacionalidad anual.

```{r ej18, echo=FALSE}
df_ts <- ts(df$TG, frequency = 365, start = c(1941, 8))

acf(df_ts, main = "ACF de la Temperatura Media", lag.max = 365 * 10, na.action = na.pass)
```

Este gráfico de autocorrelación nos muestra como está correlacionada la serie temporal consigo misma en diferentes lags de tiempo. Como tenemos datos diarios hemos utilizado lags diarios. Como queremos ver si hay estacionalidad anual, cada unidad del lag representa un año. Por tanto, como podemos observar, hay una clara estacionalidad anual. Esto es de esperar pues estamos hablando de temperatura. Por eso, la autocorrelación aumenta en aquellos puntos en los que la estación sea la misma en distintos años, y disminuye cuando las estaciones sean muy diferentes en temperatura (por ejemplo verano e invierno). Solamente hemos mostrado los diez primeros años para que la visualización sea mejor, pero es suficiente para afirmar que existe estacionalidad en la serie.

## Ejercicio 2
**¿Parece que hay tendencia? Estimar la tendencia utilizando un modelo lineal y un filtro de media móvil (teniendo cuidado con los valores NA).**

```{r ej21, echo=FALSE}
# Cálculo de la media móvil simple
df_clean$TG_ma <- rollmean(df_clean$TG, k = 365, fill = NA)

# Ajuste de un modelo lineal para la tendencia
modelo_lineal <- lm(TG ~ as.numeric(DATE), data = df_clean)

# Gráfico de la serie original, la media móvil y la tendencia
plot(df_clean$DATE, df_clean$TG, type = "l", col = "blue", 
     xlab = "Fecha", ylab = "Temperatura Media (TG)", 
     main = "Evolución de la Temperatura Media")
lines(df_clean$DATE, df_clean$TG_ma, col = "red", lwd = 2)  # Media móvil
abline(modelo_lineal, col = "green", lwd = 2)  # Línea de tendencia del modelo lineal

# Leyenda para identificar las líneas
legend("topright", legend = c("Serie Original", "Media Móvil (k=365)", "Línea de Tendencia (Modelo Lineal)"),
       col = c("blue", "red", "green"), lty = 1)
```

Al contar ahora con la media móvil y el modelo lineal podemos ver que existe una tendencia al alza en los referido a la temperatura media, que va aumentando paulatinamente con los años. Esto no se podía ver en la señal original dado que las distintas estaciones enmascaran esta tendencia.

```{r ej22, echo=FALSE}
summary(modelo_lineal)
```
Aquí podemos ver algunos de los parámetros más relevantes del modelo lineal generado.
Los residuos por ejemplo nos indican que existe una gran variedad, lo que se puede deber a la tendencia al alza de las temperaturas a lo largo de los años. Además también podemos ver los parámetros estimados del modelo.

## Ejercicio 3
**Analizar la varianza: ¿parece ser constante?**

```{r ej31, echo=FALSE}
# Como hemos analizado esa estacionalidad anual vamos a relacionar esto con la varianza analizándola de manera anual
df_clean$year <- format(df_clean$DATE, "%Y")

# Calcular varianza por año
var_por_año <- tapply(df_clean$TG, df_clean$year, var)
# Definimos los años 
years<-unique(df_clean$year)
plot(years,var_por_año, type = "b", col = "blue", 
     xlab = "Año", ylab = "Varianza de TG", 
     main = "Varianza de la Temperatura Media por Año")
```

Como vemos la varianza de los datos van variando sin aparente relación. No obstante, vamos a calcular la correlación para estar 100% seguros de esto.

```{r ej32, echo=FALSE}
# Graficar la autocorrelación de las varianzas anuales
acf(var_por_año, main = "Autocorrelación de las Varianzas Anuales de TG")
```
Como vemos aquí se observan algunos picos aislados pero por lo general el valor de la correlación es cero, lo que es consistente con lo mencionado arriba.

## Ejercicio 4
**Antes de continuar con el análisis, transformar la serie temporal en una serie regular con una frecuencia fija (el problema es que distintos años tienen diferentes números de días). Para ello, agregamos la serie temporal en 36 puntos por año, promediando los días de cada mes en tres periodos de aproximadamente 10 días. Es decir, para cada mes se promedian (con la media) las observaciones en tres periodos: desde el 1 hasta el 10, desde el 11 hasta el 20, y desde el 21 hasta el final del mes (este último periodo puede tener una longitud variable). Las funciones `summarise` en combinación con `group_by` del paquete `dplyr` pueden ser útiles para esta operación.**

Primero, crearemos un nuevo DataFrame con los promedios calculados de cada periodo tal como indica el enunciado.

```{r ej41, echo=FALSE, message=FALSE, warning=FALSE}
df_avg <- df %>% mutate(day = day(DATE), month= month(DATE), year = year(DATE), period = ifelse(day<=10,'1-10',ifelse(day<=20,'11-20','21-fin'))) %>% # Creamos nuevas columnas con el día, mes, año y los periodos de cada mes
  group_by(year,month,period) %>% # Agrupamos por año, mes y periodo
  summarise(avg_TG = mean(TG, na.rm = TRUE)) %>% # Calculamos el promedio para cada periodo
  ungroup()
  
print(df_avg) 
```

Como podemos observar, hay muchos registros que tienen en la columna 'avg_TG' el término NaN. Esto se debe a que en cada uno de los respectivos periodos solo había valores faltantes NA, por eso al calcular el promedio de los valores faltantes el resultado és NaN ('not a number').

A continuación, creamos una serie regular usando los promedios calculados. Como tenemos tres periodos por mes y cada año tiene doce meses tendremos una serie con frecuencia fija 36.

```{r ej42, echo=FALSE}
df_avg_ts <- ts(df_avg$avg_TG, start = c(min(df_avg$year), 25), frequency = 36)

plot(df_avg_ts, main = "Serie Temporal Promediada", ylab = "Temperatura Media Promediada", xlab = "Tiempo")
```

## Ejercicio 5
**Descomponer la serie en tendencia, estacionalidad y residuos. Estudiar los residuos y la tendencia.**

Como hemos comentado antes, nuestro DataFrame df_avg tenía valores de tipo NaN, por tanto, nuestra serie temporal df_avg_ts también los tiene. Además, se puede observar en df_avg que estos valores faltantes están muy juntos. En 1942, tenemos todos los periodos desde el segundo mes hasta el octavo lleno de valores faltantes. Además, desde el décimo mes hasta el fin de año también tenemos todos los periodos llenos de NaN. Esto provoca que prácticamente todo el año 1942 esté sin registros. Esto puede suponer un problema para este ejercicio, ya que queremos analizar la serie descomponiéndola en tendencia, estacionalidad y residuos, y para esta tarea necesitamos tener una serie continua. Para solventar este problema pensamos que la mejor solución es la imputación, ya que con la eliminación perderíamos casi todos los registros de un año entero. Para realizar la imputación, utilizaremos la función 'na.seasplit' de la librería 'imputeTS', que basa la imputación en patrones estacionales. Como hemos probado que nuestra serie tiene estacionalidad anual, esta función imputa los valores faltantes basándose en los datos de otros años en los mismos meses o periodos.  


```{r ej51, echo=FALSE}
# Imputar valores faltantes respetando estacionalidad
df_avg_ts_clean <- na_seasplit(df_avg_ts)

# Descomponemos la serie en tendencia, estacionalidad y residuos.
serie_desc <- decompose(df_avg_ts_clean)

plot(serie_desc)
```

Primero vamos a analizar los residuos. Los residuos deberían ser cercanos a ruido blanco, es decir, no deberían mostrar patrones claros ni autocorrelación significativa. 

```{r ej52, echo=FALSE}
# Graficar los residuos
plot(serie_desc$random, main = "Residuos de la serie temporal", ylab = "Residuos", xlab = "Tiempo")

# Autocorrelación de los residuos
acf(na.omit(serie_desc$random), main = "ACF de los residuos")
```

Notamos que a simple vista los residuos sí que se asemejan a ruido blanco. Para estar seguros, hemos echo un gráfico de autocorrelación. Como era de esperar no parece haber una autocorrelación significativa en los residuos.

A continuación analizaremos la tendencia.

```{r ej53, echo=FALSE}
# Graficar la tendencia
plot(serie_desc$trend, main = "Tendencia de la serie temporal", ylab = "Tendencia", xlab = "Tiempo")
```

Se puede observar que la serie tiene una clara tendencia creciente.

## Ejercicio 6
**¿Hay evidencia del cambio climático en estas observaciones? Es decir, ¿parece haber un calentamiento a lo largo del tiempo? Responder analizando la información obtenida hasta ahora y, eventualmente, utilizando otros métodos.**

```{r ej61, echo=FALSE}
# Graficar la tendencia
plot(serie_desc$trend, main = "Tendencia de la serie temporal", ylab = "Tendencia", xlab = "Tiempo")
```

Con el gráfico de la tendencia podemos observar el efecto del cambio climático, ya que muestra una tendencia ascendente claramente definida. Esto indica que, desde 1940 hasta 2024, ha habido un cambio significativo en la temperatura de aproximadamente 4 grados Celsius (40 décimas de grado Celsius). Esta variación refleja un patrón que es consistente con el calentamiento global, caracterizado por un aumento progresivo de las temperaturas a lo largo de las últimas décadas.

Adicionalmente, podemos constatar este cambio de los 10 primeros años con respecto a los 10 últimos comparando los valores de temperatura media en ambos casos:

```{r ej62, echo=FALSE}
df_clean$year<-as.numeric(df_clean$year)
# Calcular la diferencia entre años
min_year <- min(df_clean$year, na.rm = TRUE) # Encuentra el año más pequeño
df_clean <- df_clean %>% mutate(year_diff = year - min_year) # Calcula year_diff

# Promedio de temperatura en los primeros y últimos 10 años
primeros_10 <- df_clean %>% filter(year_diff <= 10)
ultimos_10 <- df_clean %>% filter(year_diff >= (max(df_clean$year_diff) - 10))

promedio_primero <- mean(primeros_10$TG, na.rm = TRUE)
promedio_ultimo <- mean(ultimos_10$TG, na.rm = TRUE)

# Mostrar la diferencia
cat("Temperatura promedio primeros 10 años en (décimas de grado Celsius):", promedio_primero, "\n")
cat("Temperatura promedio últimos 10 años en (décimas de grado Celsius):", promedio_ultimo, "\n")
cat("Diferencia de temperatura media en (décimas de grado Celsius):", promedio_ultimo - promedio_primero, "\n")
```

## Ejercicio 7

**Considerando la información hasta el año 2010, construir un modelo predictivo para la temperatura en la década 2010-2020. Contrastar la predicción obtenida con los datos observados. Comparar distintos modelos predictivos y evaluarlos en cuanto a su capacidad para predecir la temperatura de la década 2010-2020.**

El modelo más simple que pueda considerarse se basa en descomponer la serie temporal en tendencia, estacionalidad y ruido, hacer una predicción de la tendencia mediante un modelo lineal y después añadir la estacionalidad correspondiente y un ruido aleatorio. 

Para aprovechar el trabajo previo, trabajaremos directamente sobre la serie temporal que calcula las medias en intervalos de ~10 días, reutilizamos el código para calcular la nueva descomposición teniendo en cuenta solo la información hasta el año 2010:

```{r ej71, include=FALSE}
df_avg_hasta_2010 <- df_avg[df_avg$year<2010,]
df_avg_ts_hasta_2010 <- ts(df_avg_hasta_2010$avg_TG, start = c(min(df_avg_hasta_2010$year), 25), end = c(max(df_avg_hasta_2010$year), 36), frequency = 36)
df_avg_ts_clean_hasta_2010 <- na_seasplit(df_avg_ts_hasta_2010)
serie_desc_hasta_2010 <- decompose(df_avg_ts_clean_hasta_2010)

for (i in unique(df_avg_hasta_2010$year)){    # Comprobamos qué años no tienen exactamente 36 muestras
  if( sum(df_avg_hasta_2010$year == i, na.rm=TRUE) != 36 ){
    print(i)
  }
}

sum(is.na(df_avg_ts_clean_hasta_2010))        # Comprobamos que no hay ninguna entrada indefinida
```

Consideramos en primer lugar el dataframe que contiene la descomposición hasta el año 2010:

Como la la tendencia de la serie es calculada a partir de enero de 1941 entonces sabemos que el número de entradas que hay hasta enero de 2010 serán $(3\cdot 12) \cdot (2010-1941+1)$

```{r ej72, echo=FALSE}
par(mfrow = c(3,1))
plot( serie_desc_hasta_2010$trend  , type = "l", main = "Tendencia hasta 2010", xlab = "Año", ylab = "Temperatura (Cº/10)")
plot( serie_desc_hasta_2010$seasonal       , type = "l", main = "Estacionalidad hasta 2010", xlab = "Año", ylab = "Temperatura (Cº/10)")
plot( serie_desc_hasta_2010$random        , type = "l", main = "Ruido hasta 2010", xlab = "Año", ylab = "Temperatura (Cº/10)")
```

Hacemos notar que si tenemos en cuenta únicamente la información hasta 2010, entonces el dominio del modelo de descomposición aportado por el comando 'decompose' es

```{r ej73, echo=FALSE}
print(   c(min(time(serie_desc_hasta_2010$trend)), max(time(serie_desc_hasta_2010$trend))   ))
```
es decir, el modelo requiere de información previa de almenos un año y posterior de almenos 0.7 años para tener información en un punto. Estudiando más de cerca los series de trend, seasonal y random podemos ver que al principio y final de estos vectores hay 18 NAs y por tanto el modelo requiere de $36 + 18 = 54$ entradas previas y de $(1-0.306)*36 + 18 \approx 60$ entradas posteriores para calcular el valor de la descomposición en un punto. Ahora que ya podemos tener esto en cuenta procedemos ahora con el estudio previamente explicado: 

### 1. Generamos un modelo lineal para la tendencia:

```{r ej711, echo=FALSE}
df_hasta_2010 <- data.frame( time = time(serie_desc_hasta_2010$trend), trend = serie_desc_hasta_2010$trend, seasonal = serie_desc_hasta_2010$seasonal, random = serie_desc_hasta_2010$random)

modelo_tendencia<- lm(df_hasta_2010$trend ~ df_hasta_2010$time)
summary(modelo_tendencia)

plot( df_hasta_2010$time,  df_hasta_2010$trend, type = "l", main = "Tendencia hasta 2010", xlab = "Año", ylab = "Temperatura (Cº/10)")
abline(modelo_tendencia, lwd = "2", col = "blue")
legend("topleft", legend = c("Serie Original", "Línea de Tendencia (Modelo Lineal)"),
       col = c("black", "blue"), lty = 1)
```

### 2. Estudiamos la estacionalidad: para ello nos hacemos valer de la transformada de fourier rápida:

Haremos uso de la fórmula $$\Delta f = \frac{F_m}{N}$$ para calcular el incremento frecuencial (o resolución) en el eje horizontal cuando hagamos la transformada de Fourier discreta, donde $F_m$ representa la frecuencia de muestreo (en nuestro caso 36) y $N$ representa el número total de muestras en la que se calcula la transformada.

```{r ej721, echo=FALSE}
tf_season<- fft(df_hasta_2010$seasonal)
N<- length(df_hasta_2010$time)
freq_axis <- (1:N-1) * 36/N #Formula 
mod_tf_season<-Mod(tf_season)
plot(freq_axis,mod_tf_season, type = "o")
```

Se comprueba fácilmente que la frecuencia primaria de esta estacionalidad corresponde a 1 (año), cosa que reafirma nuestro sentido común. Para hacer una aproximación de la estacionalidad simplemente cogeremos consideraremos que la único coeficiente de Fourier no nulo de la estacionalidad es el asociado a la frecuencia 1.

Así, limpiamos los coeficientes no asociados a esta frecuencia

```{r ej722, echo=FALSE}
tf_season[order(mod_tf_season, decreasing= TRUE)[3:N] ]<- 0
plot(freq_axis,Mod(tf_season), xlab = "Frecuencia", ylab = "Amplitud")
```
y invertimos en Forier y comparamos con la estacionalidad original:

```{r ej723, echo=FALSE}
season_guess <- Re(fft(tf_season, inverse = TRUE))/length(tf_season)

#season_guess <- season_guess/max(abs(season_guess)) * max(abs(df_hasta_2010$seasonal))

par(mfrow = c(3,1))
plot(df_hasta_2010$time, df_hasta_2010$seasonal, main = "Estacionalidad original", xlab = "Año", ylab = "Temperatura (Cº/10)", type = "l")
plot(df_hasta_2010$time, season_guess, main = "Estacionalidad predicha", xlab = "Año", ylab = "Temperatura (Cº/10)", type = "l")
plot(df_hasta_2010$time, abs( df_hasta_2010$seasonal - season_guess), main = "Diferencia", xlab = "Año", ylab = "Temperatura (Cº/10)", type = "l")
```

Graficando vemos que las frecuencias de ambas señales son semejantes pero parecen estar ligeramente transladadas

```{r ej724, echo=FALSE}
index1975 <- which(df_hasta_2010$time == 1975)

season_anual_1<- season_guess[index1975:(index1975+35)]
```


Vemos ahora qué predicciones obtenemos para a partir del 2010 con este modelo:

```{r ej725, echo=FALSE}
time_desde_2009 <- seq(2009, max( time(df_avg_ts_clean)), by = 1/36)               # Vector de tiempos desde 2009 para que haya un poco de solapamiento

trend_guess_desde_2009 <- coef(modelo_tendencia)[1] + time_desde_2009*coef(modelo_tendencia)[2]

seasonal_guess_1_desde_2009 <- rep(season_anual_1, times=20)[1: length(time_desde_2009)] 

ts_guess_1_desde_2009 <- trend_guess_desde_2009 + seasonal_guess_1_desde_2009

ts_original_desde_2009 <- df_avg_ts_clean[  which(time(df_avg_ts_clean)  == 2009 ): length(df_avg_ts_clean)   ]

plot(time_desde_2009, ts_guess_1_desde_2009, type = "l", main = "", col = "blue", xlab = "Tiempo", ylab = "Temperatura (Cº/10)")
lines(time_desde_2009 ,ts_original_desde_2009, col = "red")
legend( "topleft", legend= c("Predicción", "Original"), col = c("blue", "red"), lty = 1)

par(mfrow = c(3,1))

plot(time_desde_2009, ts_guess_1_desde_2009, type = "l", main = "Predicción",xlab = "Tiempo", ylab = "Temperatura (Cº/10)")
plot(time_desde_2009 ,ts_original_desde_2009, type = "l", main= "Original",xlab = "Tiempo", ylab = "Temperatura (Cº/10)")
plot(time_desde_2009 ,abs(ts_original_desde_2009-ts_guess_1_desde_2009) , type = "l", main= "Diferencia absoluta",xlab = "Tiempo", ylab = "Temperatura (Cº/10)")
```

Otra manera en la que podemos hacer esto es cogiendo un intervalo de un único año (por ejemplo 1975) para predecir toda la estacionalidad (la que nos proporciona el comando 'decompose'):

```{r ej726, echo=FALSE}
index1975 <- which(df_hasta_2010$time == 1975)

season_anual_2<- df_hasta_2010$seasonal[index1975:(index1975+35)]
```

```{r ej727, echo=FALSE}
time_desde_2009 <- seq(2009, max( time(df_avg_ts_clean)), by = 1/36)               # Vector de tiempos desde 2009 para que haya un poco de solapamiento

trend_guess_desde_2009 <- coef(modelo_tendencia)[1] + time_desde_2009*coef(modelo_tendencia)[2]

seasonal_guess_2_desde_2009 <- rep(season_anual_2, times=20)[1: length(time_desde_2009)]

ts_guess_2_desde_2009 <- trend_guess_desde_2009 + seasonal_guess_2_desde_2009

ts_original_desde_2009 <- df_avg_ts_clean[  which(time(df_avg_ts_clean)  == 2009 ): length(df_avg_ts_clean)   ]

plot(time_desde_2009, ts_guess_2_desde_2009, type = "l", main = "", col = "blue", xlab = "Tiempo", ylab = "Temperatura (Cº/10)")
lines(time_desde_2009 ,ts_original_desde_2009, col = "red")
legend( "topleft", legend= c("Predicción", "Original"), col = c("blue", "red"), lty = 1)

par(mfrow = c(3,1))

plot(time_desde_2009, ts_guess_2_desde_2009, type = "l", main = "Predicción",xlab = "Tiempo", ylab = "Temperatura (Cº/10)")
plot(time_desde_2009 ,ts_original_desde_2009, type = "l", main= "Original",xlab = "Tiempo", ylab = "Temperatura (Cº/10)")
plot(time_desde_2009 ,abs(ts_original_desde_2009-ts_guess_2_desde_2009) , type = "l", main= "Diferencia absoluta",xlab = "Tiempo", ylab = "Temperatura (Cº/10)")
```

A simple vista es difícil evaluar que modelo ajusta mejor a la realidad, por esto, calculamos los residuos al cuadrado:

```{r ej728, echo=FALSE}
Residue_1 <- sum(abs( ts_guess_1_desde_2009 - ts_original_desde_2009 ))
Residue_1
Residue_2 <- sum(abs( ts_guess_2_desde_2009 - ts_original_desde_2009 ))
Residue_2
```

Vemos que el segundo modelo muestra un ajuste más preciso. Por esto, consideraremos a partir de ahora la versión "2" de la estacionalidad.
Por último, generamos un vector aleatorio con distribución normal centrada en 0 y que tenga como varianza la varianza del elemento aleatorio de la serie temporal.
Esto lo podemos hacer de varias maneras. La más sencilla es:

```{r ej729, echo=FALSE}
random_guess <- rnorm( length( ts_original_desde_2009  ), mean = 0, sd = sd( serie_desc_hasta_2010$random, na.rm=TRUE))

ts_guess_2_desde_2009_con_random <- trend_guess_desde_2009 + seasonal_guess_2_desde_2009+random_guess

par(mfrow = c(3,1))

plot(time_desde_2009, ts_guess_2_desde_2009, type = "l", main = "Predicción sin ruido",xlab = "Tiempo", ylab = "Temperatura (Cº/10)")
plot(time_desde_2009 ,ts_original_desde_2009, type = "l", main= "Original",xlab = "Tiempo", ylab = "Temperatura (Cº/10)")
plot(time_desde_2009 ,ts_guess_2_desde_2009_con_random , type = "l", main= "Predicción con ruido",xlab = "Tiempo", ylab = "Temperatura (Cº/10)")

#Calculando los residuos obtenemos un valor de 
Residue_3 <- sum( abs( ts_guess_2_desde_2009_con_random - ts_original_desde_2009) )
Residue_3
```

Para asegurarnos que el resultado no depende de una observación puntual del vector aleatorio podemos repetir el proceso y calcular los residuos $n$ veces para posteriormente calcular la media de los residuos.

```{r ej7210, echo=FALSE}
n<- 1000
Residuals_Replicate <- replicate(n = n, { 
  sum( abs( trend_guess_desde_2009 + seasonal_guess_2_desde_2009  + rnorm( length( ts_original_desde_2009 ), mean = 0, sd = sd( serie_desc_hasta_2010$random, na.rm=TRUE))  - ts_original_desde_2009), na.rm=TRUE  )
  })
mean( Residuals_Replicate)
```

Vemos que aunque la forma de la señal se asemeje más a la señal original, en la práctica la predicción está más alejada de la realidad.

Otra manera de generar este vector de ruido puede ser el uso de bootstrap con el vector "random" que nos aporta la descomposición: 

```{r ej7211, echo=FALSE}
random_guess_2 <- sample( serie_desc_hasta_2010$random  , size = length(ts_original_desde_2009))

ts_guess_2_desde_2009_con_random_2 <- trend_guess_desde_2009 + seasonal_guess_2_desde_2009+random_guess_2

par(mfrow = c(3,1))

plot(time_desde_2009, ts_guess_2_desde_2009, type = "l", main = "Predicción sin ruido",xlab = "Tiempo", ylab = "Temperatura (Cº/10)")
plot(time_desde_2009 ,ts_original_desde_2009, type = "l", main= "Original",xlab = "Tiempo", ylab = "Temperatura (Cº/10)")
plot(time_desde_2009 ,ts_guess_2_desde_2009_con_random_2 , type = "l", main= "Predicción con ruido",xlab = "Tiempo", ylab = "Temperatura (Cº/10)")

#Calculando los residuos obtenemos un valor de 
Residue_4 <- sum( abs( ts_guess_2_desde_2009_con_random_2 - ts_original_desde_2009) , na.rm=TRUE)
Residue_4
```

A priori este residuo parece más bajo, pero comprobamos la consistencia de esta suposición mediante réplicas:

```{r ej7212, echo=FALSE}
n <- 1000
Residuals_Replicate_2 <- replicate(n = n, { 
  sum( abs( trend_guess_desde_2009 + seasonal_guess_2_desde_2009  + sample( serie_desc_hasta_2010$random  , size = length(ts_original_desde_2009))  - ts_original_desde_2009), na.rm=TRUE  )
  })
mean( Residuals_Replicate_2)
```

Efectivamente este modelo para predecir el ruido parece mejor que el anterior.

Con lo que en caso de preferir una predición con ruido, nuestra predicción final queda como

```{r ej7213, echo=FALSE, message=FALSE, warning=FALSE}
plot(time_desde_2009 ,ts_guess_2_desde_2009_con_random_2 , type = "l", main= "Predicción con ruido",xlab = "Tiempo", ylab = "Temperatura (Cº/10)")
lines(time_desde_2009, trend_guess_desde_2009)
```
en caso de querer una más conservadora, simplemente obviariamos el ruido, quedando como:
```{r ej7214, echo=FALSE, message=FALSE, warning=FALSE}
plot(time_desde_2009 ,ts_guess_2_desde_2009 , type = "l", main= "Predicción sin ruido",xlab = "Tiempo", ylab = "Temperatura (Cº/10)")
lines(time_desde_2009, trend_guess_desde_2009)
```

## Ejercicio 8

**Proporcionar una estimación de la temperatura hasta el año 2030. En particular, proporcionar una estimación de la temperatura para todos los meses del año 2030. Utilizar el mejor modelo obtenido en el punto anterior. Intentar también proporcionar una estimación de la confianza o incertidumbre de las predicciones.**

Comencemos prediciendo el valor de la temperatura hasta el año 2030.

```{r ej81, echo=FALSE}
#Creamos el modelo lineal desde cero para no obtener problemas
x <- as.numeric(df_hasta_2010$time)
y <- as.numeric(df_hasta_2010$trend)
mt <- lm(y ~ x)

#Creamos dos vectores de tiempo
time_desde_2009_hasta_2030 <- seq(2009, 2031-1/36, by = 1/36)
time_desde_2009_hasta_2024 <- seq(2009, 2024-1/36, by = 1/36)

#Predecimos los nuevos valores de trend
new_data <- data.frame(x = time_desde_2009_hasta_2030)
trend_guess_desde_2009_hasta_2030 <- predict(mt, newdata = new_data, interval = "confidence", level = 0.95)

#Juntamos los valores en la predicción final
seasonal_guess_2_desde_2009_hasta_2030 <- rep(season_anual_2, times=22)[1: length(time_desde_2009_hasta_2030)]
ts_guess_2_desde_2009_hasta_2030 <- trend_guess_desde_2009_hasta_2030 + seasonal_guess_2_desde_2009_hasta_2030
ts_guess_2_completo <- ts_guess_2_desde_2009_hasta_2030[,1]
ts_guess_2_completo[1:length(time_desde_2009_hasta_2024)] <- rep(NA,length(time_desde_2009_hasta_2024))

ts_original_desde_2009_hasta_2024 <- df_avg_ts_clean[which(time(df_avg_ts_clean)  == 2009 ): length(df_avg_ts_clean)]

#Representamos la predicción junto con el valor original
plot(time_desde_2009_hasta_2030, ts_guess_2_completo, type = "l", main = "", col = "blue", xlab = "Tiempo", ylab = "Temperatura (Cº/10)")
lines(seq(2009, 2024 + 2/36, by = 1/36)  ,ts_original_desde_2009_hasta_2024, col = "red")
legend( "topleft", legend= c("Predicción", "Original"), col = c("blue", "red"), lty = 1)
```

Centremonos ahora exclusivamente en la predicción del año 2030

```{r ej82, echo=FALSE}
time_2030 <- time_desde_2009_hasta_2030[which(time_desde_2009_hasta_2030  == 2030 ): length(ts_guess_2_completo)]

fraction <- time_2030 - 2030  # Decimal part (0.5)
year <- floor(time_2030)  # Integer part (2024)

# Calculate the day of the year (365 or 366 days for leap years)
days_in_year <- ifelse(lubridate::leap_year(time_2030), 366, 365)
day_of_year <- round(fraction * days_in_year)

# Convert day of the year to a date
date <- as.Date(paste0(year, "-01-01")) + (day_of_year - 1)

#Representamos la predicción del año 2030
plot(date, ts_guess_2_completo[which(time_desde_2009_hasta_2030  == 2030 ): length(ts_guess_2_completo)], type = "l", main = "", col = "blue", xlab = "Tiempo", ylab = "Temperatura (Cº/10)")
legend( "topleft", legend= c("Predicción"), col = c("blue"), lty = 1)
```

Si bien podríamos tratar de representar el intervalo de confianza al 95% con el que obtenemos nuestras predicciones, esto no sería del todo correcto, pues la anchura media de estos intervalos es de 0.1ºC. Aún así, este análisis respalda la certeza de nuestras predicciones.

```{r ej83, include=FALSE}
mean(ts_guess_2_desde_2009_hasta_2030[,2]-ts_guess_2_desde_2009_hasta_2030[,3])
```

